{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensors\n",
    "## Creating tensors\n",
    "\n",
    "Pytorch tensor are created using `torch.Tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "\n",
    "TENSOR = torch.tensor([[[1, 2, 3], \n",
    "                        [4, 5, 6], \n",
    "                        [7, 8, 9]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ndims: 4\n",
      "Shape: torch.Size([2, 2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "EXPANDED_TENSOR = torch.Tensor([[[[1, 2], [3, 4], [5, 6]], \n",
    "                                [[7, 8], [9, 10], [11, 12]]],\n",
    "                                [[[1, 2], [3, 4], [5, 6]], \n",
    "                                [[7, 8], [9, 10], [11, 12]]]])\n",
    "\n",
    "print(\"Ndims:\", EXPANDED_TENSOR.ndim)\n",
    "print(\"Shape:\", EXPANDED_TENSOR.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important, because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those ranodm numbers to better represent the data.\n",
    "\n",
    "The process is:\n",
    "`Start with random numbers -> look at data -> update random numbers -> update those numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5850, 0.5363, 0.3874, 0.0532],\n",
       "        [0.0094, 0.3720, 0.5263, 0.7833],\n",
       "        [0.8171, 0.5652, 0.4068, 0.8262]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create random tensors of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3, 224, 224)) # height, width, colour channels\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zero = torch.zeros(size=(3, 4))\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,  78, 155, 232, 309, 386, 463, 540, 617, 694, 771, 848, 925])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange() since range() is deprecated\n",
    "one_to_ten = torch.arange(start=1, end=1000, step=77)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note**: A tensor operation might fail beacause of of these datatypes errors:\n",
    "1. Tensors not the right datatype\n",
    "2. Tensors not the right shape\n",
    "3. Tensors not on the right device\n",
    "\n",
    "A more precise datatype takes more memory and is slower in computing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor: even if the datatype is specified as None, the default type will always be float\n",
    "\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # what datatype is the tensor \n",
    "                               device=None, # What device is your tensor on\n",
    "                               requires_grad=False) # whether or not track gradients with tensors operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(dtype=torch.float16)\n",
    "\n",
    "float_16_tensor*float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = float_32_tensor.type(dtype=torch.int32)\n",
    "\n",
    "int_32_tensor*float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensor (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor + 10)\n",
    "# create a tensor and multiply by 10 to it\n",
    "print(tensor * 10)\n",
    "# Same goes for multiplication and division"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and DL:\n",
    "\n",
    "1. Element-wise multiplication: multiply an scalar to the whole matrix.\n",
    "2. Matrix multiplication: Dot product between de columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6984, 0.2641, 0.5343]]) * tensor([[0.6984, 0.2641, 0.5343]])\n",
      "Equals: tensor([[0.4878, 0.0698, 0.2854]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "tensor = torch.rand(size=(1, 3))\n",
    "print(f\"{tensor} * {tensor}\")\n",
    "print(f\"Equals: {tensor*tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8430]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor.T) # use the atribute \"T\" to transpose the tensor dim goes from 1,3 to 3, 1, enabling matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8430]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor, tensor.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative operations with tensors\n",
    "\n",
    "* min: extracts the smallest value of the tensor  \n",
    "* max: extracts the greates value of the tensor  \n",
    "* mean: extracts the mean from the values of the tensor\n",
    "* sum: adds all the values from the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min of the tensor is: 0.2641461491584778\n",
      "The max of the tensor is: 0.6983973383903503\n",
      "The mean of the tensor is: 0.4989376962184906\n",
      "The sum of the tensor is: 1.4968130588531494\n"
     ]
    }
   ],
   "source": [
    "print(f\"The min of the tensor is: {tensor.min()}\")\n",
    "print(f\"The max of the tensor is: {tensor.max()}\")\n",
    "print(f\"The mean of the tensor is: {tensor.mean()}\")\n",
    "print(f\"The sum of the tensor is: {tensor.sum()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the positional min and max of the tensor\n",
    "* argmin: Gets the argument of the smallest value in the tensor\n",
    "* argmax: Gets the argument of the greatest value in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The position of the smallest argument is: 1\n",
      "The position of the greatest argument is: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The position of the smallest argument is: {tensor.argmin()}\")\n",
    "print(f\"The position of the greatest argument is: {tensor.argmax()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on the top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - remove all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimnesions permuted (swapped) in a certai way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra 9 dimension(s)\n",
    "x_reshaped = x.reshape(9, 1)\n",
    "x_reshaped, x_reshaped.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " torch.Size([5, 2]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 11.)\n",
    "x_reshaped = x.reshape(5, 2)\n",
    "x_reshaped, x_reshaped.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view, z shares the same memory as x\n",
    "z = x.view(1, 10)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memory as the original)\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  5.,  5.],\n",
       "        [ 2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.],\n",
       "        [ 8.,  8.,  8.],\n",
       "        [ 9.,  9.,  9.],\n",
       "        [10., 10., 10.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 4, 1],\n",
       "        [4, 5, 6, 2],\n",
       "        [7, 8, 9, 3]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = torch.tensor([[1, 2, 4], [4, 5, 6], [7, 8, 9]])\n",
    "Y_val = torch.tensor([[1], [2], [3]])\n",
    "\n",
    "dataset = torch.hstack([x_val, Y_val])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 4],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = torch.tensor([[1, 2, 4], [4, 5, 6], [7, 8, 9]])\n",
    "Y_val = torch.tensor([1, 2, 3])\n",
    "\n",
    "dataset = torch.vstack([x_val, Y_val])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[[1, 2, 3, 4, 5, 6, 7, 8]]])\n",
      "Tensor shape: torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "x_2squeeze = torch.tensor([[[1, 2, 3, 4, 5, 6, 7, 8]]])\n",
    "print(f\"Previous tensor: {x_2squeeze}\")\n",
    "print(f\"Tensor shape: {x_2squeeze.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squeezed tensor: tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "Tensor shape: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "x_squeezed = x_2squeeze.squeeze() \n",
    "print(f\"Squeezed tensor: {x_squeezed}\")\n",
    "print(f\"Tensor shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed tensor: tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
      "Tensor shape: torch.Size([1, 8])\n",
      "Unsqueezed tensor: tensor([[[1, 2, 3, 4, 5, 6, 7, 8]]])\n",
      "Tensor shape: torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "# Now we go back to the previous tensor, the unsqueezed one\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"Unsqueezed tensor: {x_unsqueezed}\")\n",
    "print(f\"Tensor shape: {x_unsqueezed.shape}\")\n",
    "\n",
    "# we still miss one dimension, maybe unsqueeze again? Yes, it seems like when we unsqueeze we add an extra dimension\n",
    "# on the higher dimension available in the tensor.\n",
    "\n",
    "x_unsqueezed = x_unsqueezed.unsqueeze(dim=0)\n",
    "print(f\"Unsqueezed tensor: {x_unsqueezed}\")\n",
    "print(f\"Unsqueezed tensor shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-permuted tensor shape: torch.Size([224, 224, 3])\n",
      "Permuted tensor shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Permute, where the dimensions of the tensor are rearrange in an specified fashion\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis such as dim 0 -> 1, 1 -> 2, 2 -> 0\n",
    "\n",
    "print(f\"Non-permuted tensor shape: {x_original.shape}\")\n",
    "print(f\"Permuted tensor shape: {x_permuted.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors)\n",
    "\n",
    "- What if we want to select specific coordinates from the tensor i.e the 1st row or the 2nd column? We need indexing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Indexing values goes from outer dimensions to inner ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's print the 1st bracket: tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Let's print the 2nd bracket: tensor([1, 2, 3])\n",
      "Let's print the 3rd bracket: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Let's print the 1st bracket: {x[0]}\")\n",
    "print(f\"Let's print the 2nd bracket: {x[0][0]}\")\n",
    "print(f\"Let's print the 3rd bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when we index based on the first coordinate, the other two remain. One we fix the first index `x[0]`, we can select the second index, that holds the 3 arrays with three values each. If we fix both of them `x[0][0]` (with the first position), then we are getting the the first element of the tensor (the array of list of arrays), and selecting the first array of them. In that array, we select the first element `x[0][0][0]` giving us the value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the first list of the tensor: tensor([[1, 2, 3]])\n",
      "Getting all the values from the 2nd tensor tensor([[2, 5, 8]])\n",
      "Getting the 2nd value from the 2nd tensor tensor([5])\n"
     ]
    }
   ],
   "source": [
    "# we can also index based on slices\n",
    "\n",
    "print(f\"Getting the first list of the tensor: {x[:, 0]}\")\n",
    "print(f\"Getting all the values from the 2nd tensor {x[:, :, 1]}\")\n",
    "print(f\"Getting the 2nd value from the 2nd tensor {x[:, 1, 1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy\n",
    "\n",
    "As NumPy is so popular, PyTorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, want it in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1., 8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor to numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility\n",
    "\n",
    "The initialization in neural networks it is based on random values to the parameters of the model. Now, what if we wnt to reproduce results? We need reproducibility.\n",
    "\n",
    "To do this, we need to fix the seed of the randomness. The seed is what generates random values (although computers are deterministic, so pseudo-random would be a better term to fit the description), is a changing term that is used to generate random values. But if fixed, then the values produced are always the same.\n",
    "\n",
    "Let's see some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.2070, 0.5792, 0.5622, 0.9885],\n",
      "        [0.9637, 0.6667, 0.2693, 0.0045],\n",
      "        [0.4841, 0.4158, 0.5762, 0.0939]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.3645, 0.9921, 0.8637, 0.4291],\n",
      "        [0.7247, 0.9274, 0.9582, 0.2932],\n",
      "        [0.6865, 0.2334, 0.6502, 0.3221]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the values of 2 random tensors are different, here is where `torch.manual_seed(seed)` comes into play. We fix the seed to some value, and then we generate the tensors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Set the random seed\n",
    "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like now, we have to equal tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-ml-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06cd4b855c78f149d1ad6fbf42b909deac9f616782983528efa5fd156873a734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
